{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9 - GPT\n",
    "\n",
    "In this assignment, you will use various transformer models for semantic search and for language generation. We will be using the `transformers` python package from huggingface; **note** that this package will automatically download language models as required the first time the code is run, and they can be quite large. (The entire assignment might download a few GB.) You might want to do this on campus, depending on your internet situation.\n",
    "\n",
    "This assignment is to be done individually. You may discuss the project with your classmates, but the work you turn in should be your own.\n",
    "\n",
    "\n",
    "# Using Generative Language Models\n",
    "\n",
    "## Goal\n",
    "\n",
    "To learn about how generative language models can be used in practice, focusing on GPT-2, which is feasible to run locally without a graphics card.\n",
    "\n",
    "## Setup\n",
    "\n",
    "This part uses the `transformers` package which can be installed with conda or pip.\n",
    "\n",
    "## Questions (100 pts)\n",
    "\n",
    "1. Write a script that generates a \"story\" using a local GPT-2 model. Your story should: 1) be at least 100 words long; 2) not have repeated phrases; and 3) be the same every time your script is run. It might be nonsensical and/or hilarious. Use the skeleton code provided below as a starting point, and <https://huggingface.co/blog/how-to-generate> as a reference document.\n",
    "\n",
    "## Part 2 Deliverables\n",
    "\n",
    "Submit your notebook as an attachment on OWL as well as a PDF version of the notebook.\n",
    "\n",
    "---\n",
    "\n",
    "# Checklist\n",
    "\n",
    "Your owl submission should include the following attachments and no additional files:\n",
    "```\n",
    "Assignment9.ipynb\n",
    "Assignment9.pdf\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython.display import display, Markdown\n",
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel, set_seed\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Welcome to Fight Club. The first rule of Fight Club is: you do not talk about Fight Club. The second rule of Fight Club is: you DO NOT talk about Fight Club!  You do not talk about Fight Club.  You do not talk about Fight Club.  You do not talk about Fight Club.  You do not talk about Fight Club. \n"
     ]
    }
   ],
   "source": [
    "# encode context the generation is conditioned on\n",
    "model_inputs = tokenizer('Welcome to Fight Club. The first rule of Fight Club is: you do not talk about Fight Club. The second rule of Fight Club is: you DO NOT talk about Fight Club! ', return_tensors='pt').to(torch_device)\n",
    "\n",
    "# generate 40 new tokens\n",
    "greedy_output = model.generate(**model_inputs, max_new_tokens=40)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "# activate beam search and early_stopping\n",
    "sample_outputs = model.generate(\n",
    "    **model_inputs,\n",
    "    max_length=200,  # Targeting 100+ words\n",
    "    num_beams=5,     # Beam search for diversity and fluency\n",
    "    no_repeat_ngram_size=2,  # Prevent phrase repetition\n",
    "    temperature=0.7,  # Add controlled randomness\n",
    "    top_k=50,         # Restrict sampling to top-k tokens\n",
    "    early_stopping=True,\n",
    ")\n",
    "# Decode and display the story\n",
    "story = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My GPT-2 Story:\n",
      "---------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Story:**\n",
       "\n",
       "Welcome to Fight Club. The first rule of Fight Club is: you do not talk about Fight Club. The second rule of Fight Club is: you DO NOT talk about Fight Club!  If you want to be a part of a fight club, you have to do it in a way that makes you feel good about yourself and your team.\n",
       "I'm not going to go into all the details of how to get involved in Fight Clubs, but here are a few things you should know:\n",
       "1. Don't be afraid to ask questions. If you don't know what you're talking about, it's probably not a good idea to start a conversation with someone who doesn't understand your point of view. \n",
       "2. Be open to new ideas. There are plenty of people out there who are willing to share their ideas with you, and there are lots of other people who will be interested in your ideas, too. You can find out more about how you can join a Fight"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_decoded_tokens(dt):\n",
    "    display(Markdown(dt))\n",
    "\n",
    "print(\"My GPT-2 Story:\")\n",
    "print(\"---------------\")\n",
    "\n",
    "## Replace 'None' with your story; this just wraps the text\n",
    "## to make it easier to read\n",
    "show_decoded_tokens(f\"**Story:**\\n\\n{story}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
